{"engine": "vllm", "max_tokens": 300, "mode": "chat", "model": "llm-jp/llm-jp-3-1.8b-instruct", "num_examples": 20, "stop": ["Q:"], "temperature": 1.0, "top_p": 0.98}
