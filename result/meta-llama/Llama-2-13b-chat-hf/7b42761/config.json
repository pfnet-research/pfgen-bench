{"engine": "vllm", "max_tokens": 300, "mode": "completion", "model": "meta-llama/Llama-2-13b-chat-hf", "num_examples": 20, "prefix": "", "stop": ["Q:", "\n\n"], "temperature": 1.0, "top_p": 0.98}
